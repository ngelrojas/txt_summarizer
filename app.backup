import os
import uvicorn
from fastapi import FastAPI, HTTPException

from summarize.summarize_response import SummarizeResponse
from summarize.summarize_request import SummarizeRequest
from extract_files.extract_text_file_pdf import extract_text_from_pdf
from langchain_ollama import ChatOllama

app = FastAPI()
llm = ChatOllama(model="llama3")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

@app.post("/summarize", response_model=SummarizeResponse)
async def summarize(req: SummarizeRequest):

    if not os.path.isfile(req.file_path):
        raise HTTPException(status_code=404, detail="File not found")

    ext = os.path.splitext(req.file_path)[1].lower()
    if ext == ".pdf":
        raw_text = extract_text_from_pdf(req.file_path)
    else:
        with open(req.file_path, encoding="utf-8") as f:
            raw_text = f.read()

    if not raw_text.strip():
        raise HTTPException(status_code=404, detail="File not found")

    prompt = f"Summarizing this text:\n\n{raw_text}"
    ai_message = llm.invoke(["human", prompt])

    return SummarizeResponse(summary=ai_message.content.strip())

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=3000)
